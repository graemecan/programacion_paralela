
<!DOCTYPE html>
<html>
<head>

<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="chrome=1" />

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />


<title>Introducción</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<!-- General and theme style sheets -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/css/reveal.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/css/theme/white.css" id="theme">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/lib/css/zenburn.css">

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
}

</script>

<!--[if lt IE 9]>
<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/lib/js/html5shiv.js"></script>
<![endif]-->

<!-- Loading the mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: false }
        }
    });
    </script>
    <!-- End of mathjax configuration -->

<!-- Get Font-awesome from cdn -->
<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css">-->


        <style type="text/css">
            .container{
                        display: flex;
                      }
            .col{
                      flex: 1;
                }
            .reveal section p {
                      display: inline-block;
                      font-size: 0.6em;
                      line-height: 1.2em;
                      vertical-align: top;
                      text-align: left;
            }
            .reveal section li {
                      font-size: 0.6em;
            }
            .reveal section img {
                      border: none;
            }
        </style>

	</head>
	<body>
		<div class="reveal">
			<div class="slides">

                <section><h1>Programación Paralela</h1>
                </section>

                <section><h2>Información sobre el curso</h2>
                <p><ul><li>Libro: "Parallel Programming", Schmidt, Gonzalez-Dominguez, Hundt, Schlarb</li>
                       <li>El libro usa el lenguaje C++, nosotros usaremos C</li>
                       <!--<li>El horario de la clase es martes 10.15-11.15, miercoles 10.15-11.15.</li>-->
                       <li>Las evaluaciones serán en forma de 3 tareas y un proyecto final (si hay tiempo).</li></ul>
                </section>

                <section><h2>Programa del curso</h2>
                <p><ul><li>Introducción</li>
                       <li>Fundamentos Teóricos</li>
                       <li>Cache, vectorización (SIMD)</li>
                       <li>OpenMP</li>
                       <li>MPI</li>
                       <li>Proyecto Final</li></ul>
                </section>

                <section><h2>Introducción</h2>
                   <ul><li>Repaso del lenguaje C</li>
                       <li>Instalación de librerias, uso de Kosmos</li>
                       <li>Motivación</li>
                       <li>Conceptos básicos</li>
                       <li>Memoria distribuida/compartida</li>
                       <li>Diseño de algoritmos paralelizados</li></ul>
                </section>

                <section><h3>Repaso del lenguaje C</h3>
                </section>

                <section><h4>El proceso de compilación</h4>
                    <img src="introduction_figs/compilacion.jpeg">
                </section>

                <section><h4>Hola Mundo</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){
    printf("Hola Mundo!\n");
}</code></pre></p>
                </section>

               <section><h4>Tipos básicos de datos</h4>
                    <ul><li><code>int</code>: números enteros (2 o 4 bytes)</li>
                        <li><code>unsigned int</code>: números enteros positivos (2 o 4 bytes)</li>
                        <li><code>float</code>: números reales (4 bytes)</li>
                        <li><code>double</code>: números reales (8 bytes)</li>
                        <li><code>long double</code>: números reales (16 bytes)</li>
                        <li><code>char</code>: carácteres (número entero que es el código de un carácter, 1 byte)</li>
                        <li><code>void</code>: nada</li></ul>
               </section>

               <section><h4>Tipos básicos de datos</h4>
                    <p><span style="color: red">Ejercicio:</span></p><br>
                    <ol><li>¿Cuánto es el rango de valores que se puede guardar en un <code>int</code> de 2 bytes?</li>
                        <li>¿en un <code>uint</code> de 2 bytes?</li></ol>
               </section>

               <section><h4>Tipos enteros</h4>
                    <img src="introduction_figs/integer_types.png">
               </section>

               <section><h4>Tipos reales</h4>
                    <img src="introduction_figs/real_types.png">
               </section>

               <section><h4>Imprimir valores de variables</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){
    int numero1 = -3;
    uint numero2 = 4;
    float numero3 = 3.141;
    double numero4 = 3.141;

    printf("%d %u %f %lf\n",numero1,numero2,numero3,numero4);
}</code></pre></p>
                </section>

                <section><h4>Especificadores de formato</h4>
                    <img src="introduction_figs/especificadores.jpg">
                </section>

                <section>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){
    float numero3 = 3.141;
    double numero4 = 3.141;

    printf("%.6f %.10lf\n",numero3,numero4);
}</code></pre></p>
                </section>

                <section><h4>Tamaños de variables</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){
    int numero1;
    unsigned int numero2;
    float numero3;
    double numero4;
    long double numero5;

    printf("%lu %lu %lu %lu %lu\n",sizeof(numero1),sizeof(numero2),
                                   sizeof(numero3),sizeof(numero4),
                                   sizeof(numero5));
}</code></pre></p>
                </section>

                <section><h4>Variables enteros de tamaño fijo</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdint.h&gt

int main(){
    uint8_t numero1;
    uint16_t numero2;
    uint32_t numero3;
    uint64_t numero4;
    int64_t numero5;

    printf("%lu %lu %lu %lu %lu\n",sizeof(numero1),sizeof(numero2),
                                   sizeof(numero3),sizeof(numero4),
                                   sizeof(numero5));
}</code></pre></p>
                </section>

                <section><h4>Estructuras (tipos derivados)</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

struct vector{
    int x, y, z;
};

int main(){
    struct vector v;
    v.x = 10;
    v.y = 12;
    v.z = 15;

    printf("%d %d %d",v->x,v->y,v->z);
}</code></pre></p>
                </section>

                <section><h4>Memoria ocupada por una estructura</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

struct datos1  
{ 
    short s; // 2 bytes + 2 padding
    int i;   // 4 bytes
    char c;  // 1 byte + 3 padding
}; 
  
struct datos2  
{ 
    int i; // 4 bytes
    char c; // 1 byte
    short s; // 2 bytes + 1 padding
}; 

int main(){
    struct datos1 d1;
    struct datos2 d2;

    printf("%lu %lu\n",sizeof(d1),sizeof(d2));
}</code></pre></p>
                </section>

                <section><h4>Otros tipos: uniones</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

union datos{
   int i;
   float f;
   double g;
};

int main(){
    union datos d;

    datos.i = 10;
    datos.f = 24.2;
    datos.g = 345.6;

    printf("%d\n",datos.i);
    printf("%f\n",datos.f);
    printf("%f\n",datos.g);
    printf("%lu\n",sizeof(d));

}</code></pre></p>
                </section>

                <section><h4>Otros tipos: enums</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

enum semana{lun, mar, mie, jue, vie, sab, dom};

int main(){

    enum semana dia;
    dia = mie;

    printf("%d\n",dia);
    printf("%lu\n",sizeof(dia));

}</code></pre></p>
                </section>

                <section><h4>Punteros</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){

    int x = 10;
    int* p;

    p = &x;

    printf("%d %d\n",x,*p);
    printf("%lu %lu\n",sizeof(x),sizeof(p));

}</code></pre></p>
                </section>

                <section><h4>Arrays</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){

    int x[4];

    x[0] = 1;
    x[1] = 10;
    x[2] = 20;
    x[3] = 40;

    printf("%d %d %d %d\n",x[0],x[1],x[2],x[3]);
    printf("%lu\n",sizeof(x));

}</code></pre></p>
                </section>

                <section><h4>Arrays y su relación con punteros</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){

    int x[4];

    x[0] = 1;
    x[1] = 10;
    x[2] = 20;
    x[3] = 40;

    printf("%d %d %d %d\n",*x,*(x+1),*(x+2),*(x+3));

}</code></pre></p>
                </section>

                <section><h4>Arrays y su relación con punteros</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(){

    int* x;
    x = malloc(4*sizeof(int));

    x[0] = 1;
    x[1] = 10;
    x[2] = 20;
    x[3] = 40;

    printf("%d %d %d %d\n",*x,*(x+1),*(x+2),*(x+3));

}</code></pre></p>
                </section>

                <section><h4>Funciones</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int sumar_numeros(int a, int b){
    return a+b;
}

int main(){

    int x = 19;
    int y = 20;
    int z;

    z = sumar_numeros(x,y);

    printf("%d %d %d\n",x,y,z);

}</code></pre></p>
                </section>

                <section><h4>Funciones</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int sumar_numeros(int a, int b){
    return a+b;
}

int main(){

    int x = 19;
    int y = 20;
    int z;

    z = sumar_numeros(x,y);

    printf("%d %d %d\n",a,b,z);

}</code></pre></p>
                <p>¿Cuál es el error aquí?</p>
                </section>

                <section><h4>Visibilidad (<i>scope</i>)</h4>
                    <ul><li class="fragment">Las variables en <code>main</code> son <b>visibles</b> solamente en <code>main</code></li>
                    <li class="fragment">Las variables en <code>sumar</code> son <b>visibles</b> solamente en <code>sumar</code></li>
                    <li class="fragment">Una variable (de cualquier tipo: básica, estructura, unión, enum) declarada <b>fuera</b> de cualquier función (incluyendo <code>main</code>) tiene visibilidad en todo el código.</li>
                    <li class="fragment">Se llama una variable <b>global</b> (las otras variables son <b>locales</b>).</li></ul>
                </section>

                <section><h4>Array global</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

#define N 10000000; // diez millones

double x[N];

int main(){

    printf("%lu\n",sizeof(x));

}</code></pre></p>
                <p><span style="color: red">Ejercicio:</span> imprimir el tamaño del array x a la pantalla en MB.</p>
                </section>

                <section><h4>Array local</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

#define N 10000000; // diez millones

int main(){

    double x[N]; // declarada dentro de "main" ahora

    printf("%lu\n",sizeof(x));

}</code></pre></p>
                <p>¿Este programa corre?</p>
                </section>

                <section><h4><i>Stack</i> vs. <i>heap</i></h4>
                    <ul><li>La versión con array local no funciona por limitación de espacio de memoria asignada al proceso (programa).</li>
                        <li>Cada proceso tiene memoria de tipo <i>stack</i> y memoria de tipo <i>heap</i></li></ul>
                </section>

                <section><h4><i>Stack</i> vs. <i>heap</i></h4>
                    <div class="container">
                    <div class="col">
                    <img src="introduction_figs/stack_heap_code.png">
                    </div>
                    <div class="col">
                    <img src="introduction_figs/stack_heap.jpg">
                    </div>
                    </div>
                    <p>El espacio de <i>stack</i> está limitado para cada proceso. En linux se puede usar <code>ulimit -a</code> para ver cuanto hay.</p>
                </section>

                <section><h4>Array local asignado al <i>heap</i></h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

#define N 10000000; // diez millones

int main(){

    double* x = malloc(N*sizeof(double)); // usando el heap

    printf("%lu\n",sizeof(x));

}</code></pre></p>
                </section>

                <section><h4>Poblando un array</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){

    int x[5] = {1,2,3,4,5};

    printf("%d %d %d %d %d\n",x[0],x[1],x[2],x[3],x[4]);

}</code></pre></p>
                </section>

                <section><h4>Ciclos <code>for</code></h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int main(){

    int x[5];

    for (int i = 0; i &lt 5; i++){ //Valido para C99 en adelante
        x[i] = i+1;
    }

    for (int i = 0; i &lt 5; i++){
        printf("%d ",x[i]);
    }
    printf("\n");

}</code></pre></p>
                </section>

                <section><h4>Arrays con más dimensiones</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(){

    int xN = 4;
    int yN = 4;

    double phi[xN][yN];

    printf("%lu\n",sizeof(phi));

}</code></pre></p>
                </section>

                <section><h4>Organización de la memoria</h4>
                    <img src="introduction_figs/row-major-2D.png">
                    <ul><li>Arrays en C están guardados en "orden de fila mayor" (<i>row-major order</i>).</li>
                        <li><code>phi[xN][yN]</code> corresponde a un array de punteros...</li></ul>
                </section>

                <section><h4><code>malloc</code> con arrays bidimensional</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(){

    int xN = 4;
    int yN = 4;

    // Espacio unidimensional en la memoria
    double* phi = malloc(xN*yN*sizeof(double)); 

    printf("%lu\n",sizeof(phi));

}</code></pre></p>
                </section>

                <section><h4>Aritmetica de índices</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(){

    int xN = 4;
    int yN = 4;

    double phi1[xN][yN];
    double* phi2 = malloc(xN*yN*sizeof(double));

    for (int i = 0; i &lt xN; i++){
        for (int j = 0; j &lt yN; j++){
            phi1[i][j] = i+j;
        }
    }

    for (int i = 0; i &lt xN; i++){
        for (int j = 0; j &lt yN; j++){
            phi2[i*yN + j] = i+j;
        }
    }

    for (int i = 0; i &lt xN; i++){
        for (int j = 0; j &lt yN; j++){
            printf("%d %d %d %f %f\n",i,j,i*yN+j,phi1[i][j],phi2[i*yN + j]);
        }
    }

}</code></pre></p>
                </section>

                <section><h4>Pasar por valor</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

int actualizar_x(int x){
    return x+1;
}

int main(){

    int x = 10;
    int y;

    y = actualizar_x(x);

    printf("%d %d\n",x,y);

}</code></pre></p>
                </section>


                <section><h4>Pasar por referencia</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt

void actualizar_x(int* x){
    *x += 1;
}

int main(){

    int x = 10;
    int* p;

    p = &x;

    printf("%d\n",x);

    actualizar_x(p);

    printf("%d\n",x);

}</code></pre></p>
                </section>

                <section><h4>Pasando un array a una función</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdio.h&gt

void poblar_array(int* arr, int N){
    
    for (int i = 0; i &lt N; i++){
        arr[i] = i;
    }
}

int main(){

    int N = 10;
    int* x = malloc(N*sizeof(int));

    for (int i = 0; i &lt N; i++){
        printf("%d ",x[i]);
    }
    printf("\n");

    poblar_array(x, N);

    for (int i = 0; i &lt N; i++){
        printf("%d ",x[i]);
    }
    printf("\n");

}</code></pre></p>
                <p>
                </section>

                <section><h4>Pasando un array a una función</h4>
                    <p><span style="color: red">Ejercicio:</span> poblar un array bidimensional usando una función (pasando por referencia). Hay varios métodos...</p>
                </section>

                <section><h4>Argumentos del terminal</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(int argc, char *argv[]){

    printf("Hola Mundo! El numero es %c\n",*argv[1]);
}</code></pre></p>
                </section>

                <section><h4>Argumentos del terminal</h4>
                    <p><pre><code class="language-c">#include &ltstdio.h&gt
#include &ltstdlib.h&gt

int main(int argc, char *argv[]){
    int numero;
    if (argc &lt 2 || argc &gt 2){
        printf("Para correr el programa escribir: ./hola_mundo_numero &ltnumero&gt\n");
        exit(1);
    }

    numero = atoi(argv[1]);

    printf("El numero es %d\n",numero);
}</code></pre></p>
                </section>

                <section><h3>Instalación de librerias, uso de Kosmos</h3>
                </section>

                <section><h4>Compiladores, librerias (Linux)</h4>
                    <ul><li>Compilador: gcc (viene por defecto en Linux)</li>
                        <li>Instrucciones vectoriales: <code>more /proc/cpuinfo | grep avx</code></li>
                        <li>OpenMP: <code>sudo apt-get install libomp-dev</code> (puede venir con el compilador)</li></ul>
                        <li>MPI: <code>sudo apt install openmpi-bin openmpi-dev openmpi-common openmpi-doc libopenmpi-dev</code></li></ul>
                </section>

                <section><h4>Verificar existencia de GCC y MPI</h4>
                    <p><pre><code>gcc --version</code></pre></p>
                    <p><pre><code>mpicc --version</code></pre></p>
                </section>

                <section><h4>Verificar existencia de OpenMP</h4>
                    <p><pre><code>#include &ltstdio.h&gt
#include &ltomp.h&gt

int main(){

    #pragma omp parallel
    {
       int n;
       n = omp_get_num_threads();

       printf("Numero threads: %d\n",n);
    }

}</code></pre></p>
                <p>Compilar con <code>gcc verificar_openmp.c -o verificar_openmp.x -fopenmp</code></p>
                </section>

                <section><h4>Uso de Kosmos</h4>
                    <ul><li>Kosmos es el <i>cluster</i> del IFA.</li>
                    <li>Para tener acceso hay que mandar un correo a Edgar con el archivo <code>$HOME/.ssh/id_rsa.pub</code>.</li>
                    <li>Si el archivo no existe, genéralo con "ssh-keygen" (no usar sudo!).</li>
                    <li>Después Edgar creará una cuenta en Nebula y Kosmos.</li>
                    <li>El acceso es con <code>ssh &ltusername&gt@nebula.ifa.uv.cl</code> y después (en Nebula) <code>ssh &ltusername&gt@kosmos.ifa.uv.cl</code>.</li></ul>
                </section>

                <section><h4>Uso de Kosmos</h4>
                    <p>Cuando tengan sus cuentas en Kosmos veremos como lanzar trabajos en los servidores usando SGE (<i>Sun Grid Engine</i>, sistema de cola).</p>
                </section>

                <section><h3>Motivación - ¿por qué paralelizar?</h3>
                </section>

                <section><h4>Ejemplo - simulaciones numéricas</h4>
                <img src="introduction_figs/climate_model_grid.png">
                </section>

                <section><h4>Ejemplo - simulaciones numéricas</h4>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/A23Ro3kiB1E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                <p><a href="">Illustris</a> (simulación cosmológica): 8192 cores, 19 millones de horas CPU.</p>
                </section>

                <section><h4>Ejemplo - análisis de datos</h4>
                <img src="introduction_figs/data_model.png">
                </section>

                <section><h3>Conceptos básicos</h3>
                </section>

				<section><h3>Metricas</h3>
                <ul><li><b>Speedup</b>: $S = T(1)/T(p)$ donde $T(p)$ es el tiempo de ejecución en $p$ procesadores.</li>
                <li><b>Eficiencia</b>: $E = S/p = T(1)/(T(p) \times p)$</li>
                <li><b>Costo</b>: $C = T(p) \times p$</li>
                <li><b>Escalabilidad, fuerte</b>: como cambia la eficiencia con una cantidad fija de datos, variando $p$.</li>
                <li><b>Escalabilidad, débil</b>: como cambia la eficiencia, variando la cantidad de datos y $p$.</li>
                <li><b>Razón de cómputo-a-comunicación</b>: tiempo ocupado para cálculos dividido por tiempo ocupado en comunicación.</li></ul>
                </section>

                <section><h3>Ejemplo simple: sumar un array</h3>
                <p>Calcular $\sum_{i=0}^{n-1} A[i]$ en $p$ elementos de procesamiento (EP). Suposiciones:</p>
                <p><ul><li>Cómputo: cada EP suma dos números en su memoria local en $1$ unidad del tiempo.</li>
                       <li>Comunicación: cada EP puede mandar datos de su memoria local al memoria local de otro EP en $3$ unidades del tiempo (independiente de la cantidad).</li>
                       <li>Entrada/salida: datos en EP #0 al principio, al final recopilamos el resultado en EP #0.</li>
                       <li>Sincronización: todos los EPs operan en forma sincronizada (todos calculan, o todos comunican).</li></ul></p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Código secuencial: suma $n$ números en $n-1$ unidades del tiempo. $T(1,n) = n-1$.</p>
                <p>Se supone que $n = 2^k$ donde $k$ es un entero positivo.</p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Código paralelo en $p=2$ EPs:</p>
                <p><ul><li class="fragment">EP #0 manda la mitad del array al EP #1: $3$ $[t]$</li>
                       <li class="fragment">Cada EP calcula su suma parcial de $n/2$ elementos: $n/2 - 1$ $[t]$</li>
                       <li class="fragment">EP #1 manda su resultado al EP #0: $3$ $[t]$</li>
                       <li class="fragment">EP #0 suma las dos sumas parciales: $1$ $[t]$</li>
                       <li class="fragment">Tiempo total: $T(2,n) = 3 + n/2 - 1 + 3 + 1$. Para $n=1024$, $T(2,1024) = 518$, entonces el speedup es $T(1,1024)/T(2,1024) = 1.975$ y la eficiencia es $98.75%$.</li></ul></p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <img src="introduction_figs/example1.png" width=600>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Código paralelo en $p=4$ EPs:</p>
                <p><ul><li>EP #0 manda la mitad del array al EP #1: $3$ $[t]$</li>
                       <li class="fragment">EP #0 y EP #1 mandan (cada uno) un cuarto del array a los EPs #2 y #3: $3$ $[t]$</li>
                       <li class="fragment">Cada EP calcula su suma parcial de $n/4$ elements: $n/4 - 1$ $[t]$</li>
                       <li class="fragment">EPs #2 y #3 mandan sus sumas parciales a los EPs #0 y #1: $3$ $[t]$</li>
                       <li class="fragment">EPs #0 y #1 suman sus sumas parciales: $1$ $[t]$</li>
                       <li class="fragment">EP #1 manda su suma parcial al EP #0: $3$ $[t]$</li>
                       <li class="fragment">EP #0 suma las dos sumas parciales: $1$ $[t]$</li>
                       <li class="fragment">Tiempo total: $T(4,n) = 3 + 3 + n/4 - 1 + 3 + 1 + 3 + 1$. Para $n=1024$, $T(4,1024) = 269$, entonces el speedup es $T(1,1024)/T(4,1024) = 3.803$ y la eficiencia es $95.07%$.</li></ul></p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <img src="introduction_figs/example2.png" width=400>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Código paralelo en $p=8$ EPs:</p>
                <p>Tiempo total:</p>
                <p>$$T(8,n) = 3 + 3 + 3 + n/8 - 1 + 3 + 1 + 3 + 1 + 3 + 1$$</p> 
                <p>Para $n=1024$, $T(8,1024) = 148$, entonces el speedup es $T(1,1024)/T(8,1024) = 6.91$ y la eficiencia es $86%$.</p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Código paralelo en $p = 2^q$ EPs:</p>
                <p><ul><li>Tiempo de distribución de los datos: $3q$</li>
                       <li>Cómputo sumas locales: $n/p - 1 = 2^{k-q} - 1$</li>
                       <li>Recopilación de resultados parciales: $3q$</li>
                       <li>Suma de resultados parciales: $q$</li></ul></p>
                <p>Tiempo total: $$T(p,n) = T(2^q,2^k) = 3q + 2^{k-q} - 1 + 3q + q = 2^{k-q} - 1 + 7q$$</p>
                <p>$p \ll n \Rightarrow k \gg q$ y el término que viene del tiempo de cómputo $2^{k-q}$ domina (eficiencia es alta).</p>
                <p>$p \approx n \Rightarrow k \approx q$ y el término que viene del tiempo de comunicación $7q$ domina (eficiencia es baja).</p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <img src="introduction_figs/strong_scalability_figure.png" width="800">
                <p>Algoritmo no tiene escalabilidad fuerte</p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <p>Análisis de escalabilidad débil: aumentar la cantidad de elementos (de $1024$ a $524.288$) mientras aumentamos el número de elementos de procesamiento (de $1$ a $512$).</p>
                </section>

                <section><h4>Ejemplo simple: sumar un array</h4>
                <img src="introduction_figs/weak_scalability_figure.png">
                <p>Algoritmo tiene escalabilidad <b>débil</b>.</p>
                </section>

                <section><h4>Caso general</h4>
                <p>$\alpha > 0$ (tiempo de cómputo), $\beta > 0$ (tiempo de comunicación) [antes tuvimos $\alpha = 1$, $\beta = 3$]. Formula general:</p>
                <p>$T_{\alpha,\beta}(2^q,2^k) = \beta q + \alpha (2^{k-q} - 1) + \beta q + \alpha q = 2\beta q + \alpha (2^{k-q} - 1 + q)$</p>
                <p>Speedup: $$S_{\alpha,\beta}(2^q,2^k) = \frac{T_{\alpha,\beta}(2^0,2^k)}{T_{\alpha,\beta}(2^q,2^k)} = \frac{\alpha(2^k - 1)}{2\beta q + \alpha (2^{k-q} - 1 + q)}$$</p>
                </section>

                <section><h4>Razón de cómputo-a-comunicación</h4>
                <p>$\gamma = \alpha/\beta$. En el límite $\gamma \to 0$ el speedup tiende a cero (para $q > 0$):</p>
                <p>$$S_{\gamma}(2^q,2^k) = \frac{\gamma(2^k - 1)}{2q + \gamma(2^{k-q} - 1 + q)}$$ y $$\lim_{\gamma \to 0} S_{\gamma}(2^q,2^k) = 0$$</p>
                </section>

                <section><h4>Razón de cómputo-a-comunicación</h4>
                <p>Suponiendo $k > 0$, $A(k) = 2^k - 1 > 0$ y $B(q,k) = 2^{k-q} - 1 + q > 0$</p>
                <p>$\frac{d}{d\gamma} S_{\gamma}(2^q,2^k) = \frac{d}{d\gamma} \frac{\gamma A(k)}{2q + \gamma B(q,k)} = \frac{2qA(k)}{(2q + \gamma B(q,k))^2} > 0$</p>
                <p>Reducción de $\gamma$ reduce $S$ independientemente del número de elementos de procesamiento (i.e. mayor tiempo de comunicación implica menos speedup).</p>
                </section>

                <section><h4>Caso general, speedup máximo</h4>
                <p>Considerando $S_{\gamma}(2^q,2^k)$ como una función de $q$, hay un máximo local en $p = \frac{\gamma \ln 2}{2+\gamma}n$:</p>
                <p>$\frac{d}{dq} S_{\gamma}(2^q,2^k) = \frac{d}{dq} \frac{\gamma A(k)}{2q + \gamma (2^{k-q} - 1 + q)} = -\frac{\gamma A(k)(2-\gamma 2^{k-q}\ln 2 + \gamma)}{(2q + \gamma (2^{k-q} - 1 + q))^2} \stackrel{!}{=} 0$</p>
                <p>Entonces $2 + \gamma - \gamma 2^{k-q} \ln 2 \stackrel{!}{=} 0$ implica que $2^q = \frac{\gamma \ln 2}{2 + \gamma}2^k$.</p>
                <p>Para $\gamma = 1/3$ y $n = 1024$ como en nuestro ejemplo, $p \approx 100$ provee un speedup optimo.</p>
                </section>

                <section><h4>Conclusiones de este ejemplo</h4>
                <p><ul><li>El speedup depende tanto del número de elementos de procesamiento como $\gamma$.</li>
                       <li>El speedup típicamente aumenta con más EPs, hasta un máximo local. Más allá de eso, la comunicación reduce la eficiencia.</li>
                       <li>Un speedup optimo depende de $\gamma$. Tiempos de comunicación más largos implican que es mejor usar menos EPs.</li>
                       <li>La eficiencia de la paralelizacion depende del número de EPs y $\gamma$. Es una función monótona en ambos parámetros.</li></ul></p>
                </section>

                <section><h3>Memoria distribuida/compartida</h3>
                </section>

                <section><h4>Sistemas con memoria distribuida</h4>
                <img src="introduction_figs/distributed_memory.png">
                </section>

                <section><h4>Sistemas con memoria distribuida</h4>
                <p class="fragment">Cada EP tiene acceso directo solamente a su memoria local. Para acceder datos en la memoria de otro EP hay que implementar comunicación explícitamente.</p>
                <p class="fragment">Los CPUs están conectados a través de una red de interconexión (Infiniband, ethernet).</p>
                <p class="fragment">Acceso a datos en remoto puede ser comunicación <i>punto-a-punto</i> entre dos CPUs, o comunicación <i>colectiva</i> entre un grupo de CPUs.</p>
                <p class="fragment">Ejemplo punto-a-punto: CPU 1 llama una función para mandar datos a CPU 2, CPU 2 llama una función para recibir los datos.</p>
                <p class="fragment">Ejemplos de comunicación colectiva: un <i>broadcast</i> (transmisión) de datos de un CPU a todos los otros; cálculo de la suma global de una variable guardada en todos los CPUs.</p>
                </section>

                <section><h4>Sistemas con memoria distribuida</h4>
                <p>Para la programación paralela en memoria distribuida la solución más común es MPI (Message Passing Interface).</p>
                <p>MPI crea un número fijo de procesos al principio del programa (e.g. un proceso por CPU).</p>
                <p>Intercambios de datos punto-a-punto entre dos procesos se realizan con <code>MPI_Send</code> y <code>MPI_Recv</code>, mientras comunicación colectiva se realiza con <code>MPI_Bcast</code>, <code>MPI_Reduce</code>, <code>MPI_Gather</code>, <code>MPI_Scatter</code>.</p>
                </section>

                <section><h4>Sistemas con memoria distribuida</h4>
                <p>La partición de los datos es un problema clave en la programación de sistemas con memoria distribuida.</p>
                <img src="introduction_figs/partition_8x8_figure.png" width=500>
                <p>Ejemplo de una partición un array $8 \times 8$ en $4$ procesos: cada uno tiene una submatriz $4 \times 4$.</p>
                </section>

                <section><h4>Sistemas con memoria distribuida</h4>
                <div class="container">
                <div class="col">
                <img src="introduction_figs/stencil.png" height=300>
                </div>
                <div class="col">
                <img src="introduction_figs/partition_8x8_figure.png" height=300>
                </div>
                </div>
                <p>Código de plantilla (<i>stencil</i>): plantilla de 5 puntos requiere que cada proceso guarde una fila y columna adicional, para recibir datos de otro proceso. También tiene que mandar una fila y columna a otro proceso.</p>
                </section>

                <section><h4>Caso de estudio: ecuación de Poisson</h4>
                <p>Vamos a ver varias veces en el curso como solucionar la ecuación de Poisson numericamente, usando un algoritmo paralelizado.</p>
                <p class="fragment">Por ahora vamos a estudiar (en términos generales) como se puede implementar un algoritmo así en un sistema de memoria distribuida.</p>
                <p>La ecuación: $\nabla^2 \phi(x,y) = \rho(x,y)$ (electrostática, gravedad Newtoniana).</p>
                </section>

                <section><h4>Caso de estudio: ecuación de Poisson</h4>
                <p>Vamos a resolver la ecuación en una grilla discretizada:</p>
                <img src="introduction_figs/poisson.jpg" height=400>
                </section>

                <section><h3>Paralelismo básico: sistemas de memoria compartida</h3>
                <p>Todos los CPUs tienen acceso a un espacio común de memoria. Ejemplo: notebook con procesador de multinúcleo (Intel i3, i5, i7 etc.)</p>
                <p>Cada <i>core</i> típicamente tiene memoria (super-)local (cache de nivel 1) para reducir acceso a la memoria principal (cuello de botella de von Neumann).</p>
                <img src="introduction_figs/von_nuemann.webp" height=300>
                </section>

                <section><h3>Paralelismo básico: sistemas de memoria compartida</h3>
                <p>Con memoria compartida típicmente se utiliza <i>multithreading</i>.</p>
                <img src="introduction_figs/multithreading.jpg" height=400>
                </section>

                <section><h3>Paralelismo básico: sistemas de memoria compartida</h3>
                <p>Los hilos (threads) comparten memoria simultaneamente: hay que tener cuidado para evitar <span style="color:red">condiciones de carrera</span> (<i>race conditions</i>).
                <p>Este es cuando dos hilos acceden a la misma variable compartida simultaneamente (sin <i>locking</i> o sincronización).</p>
                </section>

                <section><h3>Paralelismo básico: sistemas de memoria compartida</h3>
                <p>Estudiaremos programación de <i>multithread</i> con <span style="color:blue">OpenMP</span>: ocupa <i>pragmas</i> para automatizar la paralelización.</p>
                <p>Pragmas son directivas al preprocesador para generar código de <i>multithread</i> para el compilador.</p>
                <p>Arquitecturas de aceleradores (co-procesadores y GPU): miles o millones de <i>threads</i> (Programación GPU, próximo semestre)</p>
                </section>

                <section><h3>Aspectos del diseño de un algoritmo paralelizado</h3>
                <p><ul><li class="fragment">Partición: hay que descomponer el problema en partes: paralelismo de datos, paralelismo de tareas, paralelismo del modelo.</li>
                       <li class="fragment">Comunicación: la forma de dividir el problema determina el tipo y frecuencia de comunicación requerida entre procesos y/o <i>threads</i>.</li>
                       <li class="fragment">Sincronización: quizás será necesario en ciertos puntos del algoritmo.</li>
                       <li class="fragment">Balanceo de carga (<i>load balancing</i>): hay que dividir el trabajo igualmente entre los procesos/threads para optimizar el uso de recursos.</li></ul></p>
                </section>

                <section><h4>Diseño del algoritmo: como paralelizar</h4>
                <p>Se puede paralelizar cálculos completamente independientes fácilmente (<i>embarrassingly parallel problems</i>). Otros son más difíciles...</p>
                <p>Considerar la <i>suma cumulativa</i>:</p>
                <pre><code class="language-c">for (i=1; i&ltn; i++) A[i] = A[i] + A[i-1]</code></pre>
                <p>Una opción: dividir el array entre los procesadores, cada procesador calcula su suma cumulativa local. Los resultados están guardados en otro array y se calcula una segunda suma cumulativa. Este proceso toma $\log_2(p)$ pasos en paralelo.</p>
                </section>

                <section><h4>Diseño del algoritmo: como paralelizar</h4>
                <img src="introduction_figs/prefix_sum_figure.png">
                </section>

                <section><h4>Diseño del algoritmo: partición de datos</h4>
                <p>Considerar el código de <i>stencil</i> que vimos antes. La partición de datos determina la estrategia de comunicación.</p>
                <p><i>Embarrassingly parallel problems</i> involucran operaciones independientes (sin comunicación) y son fáciles de paralelizar.</p>
                <img src="introduction_figs/partition_8x8_figure.png" height=300>
                </section>

                <section><h4>Diseño del algoritmo: sincronización</h4>
                <p>Considerar el código de <i>stencil</i> que vimos antes. Quizás será necesario sincronizar para asegurar que todos los valores en las filas/columnas comunicadas estén calculados antes de mandar/recibir.</p>
                <img src="introduction_figs/partition_8x8_figure.png" height=300>
                </section>

                <section><h4>Diseño del algoritmo: paralelismo de tareas</h4>
                <p>Asignar tareas distintas a cada proceso/thread.</p>
                <p>Ejemplo con clasificación de imágenes: clasificador binario diferente en cada procesador, con los resultados combinados al final.</p>
                <img src="introduction_figs/ternary_classifier_figure.png">
                </section>

                <section><h4>Diseño del algoritmo: balanceo de carga</h4>
                <p>Supongamos que la clasificación "humano/no humano" demora más que las otras dos.</p>
                <p>En un diseño con paralelismo de tarea P2 demorará más que P0 o P1. Por lo tanto P2 estará trabajando mientras P0 y P1 están sin carga: <i>mal balanceo de carga</i>.</p>
                <p>En este caso, políticas de planificación dinámica pueden ayudar.</p>
                </section>

                <section><h4>Diseño del algoritmo: paralelismo de modelo</h4>
                <img src="introduction_figs/ann_gpu_figure.png" width=400>
                <p>Redes neuronales grandes y complejas pueden exceder la memoria disponible de un GPU.</p>
                <p>Se puede implementar paralelismo del model donde los pesos de la red están distribuidas entre varios GPUs, y cada GPU trabaja en su parte del modelo.</p>
                <p>Este requiere que el vector de salida de cada capa de la red entera esté recopilado en cada GPU antes de que se pueda calcular el próximo (i.e. se requiere comunicación y sincronización).</p>
                </section>

                <section><h3>Arquitecturas modernas de HPC</h3>
                <p>Supercomputadores modernos a menudo combinan memoria distribuida y compartida (con una mezcla de CPUs y GPUs).</p>
                <p>Por lo tanto a menudo es necesario combinar varias técnicas:</p>
                <p><ul><li>Paralelización nivel nodo: memoria distribuida, MPI</li>
                       <li>Paralelización entre nodos: memoria compartida, OpenMP</li>
                       <li>Paralelización nivel acelerador: GPUs, CUDA</li></ul></p>
                </section>


			</div>
		</div>

<script>

require(
    {
      // it makes sense to wait a little bit when you are loading
      // reveal from a cdn in a slow connection environment
      waitSeconds: 15
    },
    [
      "https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/lib/js/head.min.js",
      "https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/js/reveal.js"
    ],

    function(head, Reveal){

        // Full list of configuration options available here: https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,

            transition: "slide",

            // Optional libraries used to extend on reveal.js
            dependencies: [
                { src: "https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0/plugin/highlight/highlight.js", async: true, callback: function() { hljs.initHighlightingOnLoad();} }
            ]
        });

        var update = function(event){
          if(MathJax.Hub.getAllJax(Reveal.getCurrentSlide())){
            MathJax.Hub.Rerender(Reveal.getCurrentSlide());
          }
        };

        Reveal.addEventListener('slidechanged', update);

        function setScrollingSlide() {
            var scroll = false
            if (scroll === true) {
              var h = $('.reveal').height() * 0.95;
              $('section.present').find('section')
                .filter(function() {
                  return $(this).height() > h;
                })
                .css('height', 'calc(95vh)')
                .css('overflow-y', 'scroll')
                .css('margin-top', '20px');
            }
        }

        // check and set the scrolling slide every time the slide change
        Reveal.addEventListener('slidechanged', setScrollingSlide);

    }

);
</script>
	</body>
</html>
